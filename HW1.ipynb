{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "WzajGhK3ZxPT",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# **Fundamentals of Data Science - Winter Semester 2023**\n",
    "\n",
    "\n",
    "#### Stefano D'Arrigo (TA), Edoardo De Matteis (TA), Daniele Trappolini (TA), and Prof. Fabio Galasso\n",
    "<darrigo@di.uniroma1.it> , <dematteis@di.uniroma1.it>, <daniele.trappolini@uniroma1.it>, <galasso@di.uniroma1.it>\n",
    "\n",
    "## **#1 Homework: Image Filtering and Object Identification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV6CqjqgdLUt"
   },
   "source": [
    "This first homework covers the main topics discussed in class.\n",
    "Initially, you will be dealing with the original **Image Filtering** methods (*Question 1*), then you will have to work with **Edge Detection** algorithms (*Question 2*), and lastly, you are going to operate first-hand on **Object Identification** techniques (*Question 3*).\n",
    "Additionally, the homework will contain written questions and reports where you will be asked to write down your answer in Markdown language.\n",
    "At the end of the homework there is an additional **Bonus Question** that can boost your score by **5 points**.\n",
    "\n",
    "*Note: your task is to fill in the missing code where you see `\"YOUR CODE HERE\"` and the text part `\"WRITE YOU ANSWER HERE\"` part corresponding to each subproblem and produce brief reports on the results whenever necessary.*\n",
    "\n",
    "As part of the homework, provide the answer to questions in this notebook report-like manner. After you have implemented all the missing code in the required sections, you will be able to run all the code without any errors. We kindly ask you to double-check this since **all** the delivered homework will be executed.\n",
    "\n",
    "The completed exercise should be handed in as a single notebook file. Use Markdown to provide equations. Use the code sections to provide your scripts and the corresponding plots.\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "**Submit it** by sending an email to:\n",
    "\n",
    " **<darrigo@di.uniroma1.it>** , **<dematteis@di.uniroma1.it>**, **<daniele.trappolini@uniroma1.it>**, and **<galasso@di.uniroma1.it>** **by Friday, October 27th, 23:59**.\n",
    "\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1rpge3piKN5"
   },
   "source": [
    "**Outline and Scores for #1 Homework:**\n",
    "\n",
    "\n",
    "* **Question 1: Image Filtering** *(9 points)*\n",
    "  * **Question 1.0: Warm Up** *(1 point)*\n",
    "  * **Question 1.1: 1D Filters** *(3 points)*\n",
    "  * **Question 1.2: 2D Filters** *(4 points)*\n",
    "  * **#1 Report** *(1 point)*\n",
    "\n",
    "* **Question 2: Multi-Scale Image Representations** *(9 points)*\n",
    "  * **Question 2.1: Sobel Operator** *(1 point)*\n",
    "  * **Question 2.2: Gradient Magnitude** *(1 point)*\n",
    "  * **Question 2.3: Discrete Laplacian Operator** *(2 point)*\n",
    "  * **Question 2.4: Canny Edge Detector and Template Matching** *(3 points)*\n",
    "  * **Question 2.5: Gaussian Pyramid and Multi-Scale Template Matching** *(2 points)*\n",
    "\n",
    "* **Question 3: Object Identification** *(12 points)*\n",
    "  * **Question 3.1: 3D Joint Color Histogram** *(2 points)*\n",
    "  * **Question 3.2: Types of Histograms** *(2 points)*\n",
    "  * **Question 3.3: Histogram Metrics** *(3 points)*\n",
    "  * **Question 3.4: Image Retrieval** *(3 points)*\n",
    "  * **#2 Report** *(2 points)*\n",
    "\n",
    "* **BONUS Question 4: Performance Evaluation** *(5 points)*\n",
    "  * **Question 4.1: Closest Neighbours** *(2 points)*\n",
    "  * **Question 4.2: Performance Evaluation** *(2 point)*\n",
    "  * **Question 4.3: Analysis and Report** *(1 point)*\n",
    "\n",
    "\n",
    "**TOTAL POINTS ARE 35, BONUS QUESTION INCLUDED**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2K7arzbdXst"
   },
   "source": [
    "## **Question 1: Image Filtering *(9 Points)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvSsgW5ovZ35"
   },
   "source": [
    "*Recommended libraries to use:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MKOFXJxsRmR",
    "outputId": "23b60c51-c1d4-4f40-a464-8cbe22991e0c"
   },
   "outputs": [],
   "source": [
    "# Set to True the first time you run this file to install the required packages\n",
    "install_packages = False\n",
    "if install_packages:\n",
    "    %pip install pandas pillow numpy scipy matplotlib opencv-python scikit-image scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFoam7MjsLDm"
   },
   "outputs": [],
   "source": [
    "## import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d as conv2, convolve\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.transform import resize\n",
    "from typing import List, Tuple, Optional, Dict, Union\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_A0hXS8Ld17S"
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts RGB images to grayscale.\n",
    "\n",
    "    Args:\n",
    "        rgb (np.ndarray): RGB image.\n",
    "\n",
    "    Returns:\n",
    "        gray (np.ndarray): Grayscale image.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "\n",
    "def plot_pictures(\n",
    "    imgs: List[np.ndarray],\n",
    "    xlabels: List[str],\n",
    "    nrows: int,\n",
    "    ncols: int,\n",
    "    show: bool = True,\n",
    "    cmap: Union[str, List[str]] = \"gray\",\n",
    "    vmin: Optional[float] = None,\n",
    "    vmax: Optional[float] = None,\n",
    "    same_scale: bool = False,\n",
    ") -> List[plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plots images in a grid.\n",
    "\n",
    "    Args:\n",
    "        imgs (list[np.ndarray]): List of images.\n",
    "        xlabels (list[str]): List of xlabels.\n",
    "        nrows (int): Number of rows.\n",
    "        ncols (int): Number of columns.\n",
    "        show (bool): Whether to show the plot.\n",
    "        cmap (Union[str, List[str]]): Color map.\n",
    "        vmin (float): Minimum value.\n",
    "        vmax (float): Maximum value.\n",
    "        same_scale (bool): Whether to use the same scale for all images.\n",
    "\n",
    "    Returns:\n",
    "        axs (list[matplotlib.axes._subplots.AxesSubplot]): List of axes.\n",
    "    \"\"\"\n",
    "    axs, ax = [], None\n",
    "    cmap = [cmap] * len(imgs) if isinstance(cmap, str) else cmap\n",
    "    for (i, img), xlabel, cm in zip(enumerate(imgs), xlabels, cmap):\n",
    "        sharex = ax if same_scale else None\n",
    "        sharey = ax if same_scale else None\n",
    "        ax = plt.subplot(nrows, ncols, i + 1, sharex=sharex, sharey=sharey)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        plt.sca(ax)\n",
    "        plt.imshow(img, cmap=cm, vmin=vmin, vmax=vmax)\n",
    "        axs.append(ax)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return axs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DvjznTzIaEx"
   },
   "source": [
    "#### **Question 1.0: Warm Up *(1/9 points)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_Vdz4PuCOkG"
   },
   "source": [
    "##### **Convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT5JJYr6sRmU"
   },
   "source": [
    "The convolution is defined as $f[m,n]=I \\ast g= \\sum_{k,l} I[m-k,n-l]g[k,l]$ and is a linear operator, thus the following properties hold:\n",
    "* *Homogeneity*: $T[aX]=aT[X]$\n",
    "* *Additivity* : $T[X_1+X_2]=T[X_1]+T[X_2]$\n",
    "* *Superposition*: $T[aX_1+bX_2]=aT[X_1]+bT[X_2]$\n",
    "\n",
    "Prove mathematically the additivity of convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcB_-5nhMq7S"
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "Write it in Markdown, you are encouraged to take a look at the cells in this notebook.\n",
    "You can find a cheat sheet [here](https://www.markdownguide.org/basic-syntax)\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBCdVDhfMrYr"
   },
   "source": [
    "**Exercise on convolutions**\n",
    "\n",
    "Usually, to be consistent with the definition, we use zero padding: this practice consists of adding a border of zero-valued pixels all around the edges of the input image.\n",
    "In our case, we will have\n",
    "\n",
    "\\begin{equation}\n",
    "f[m,n] =\n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 8 & 5 & 2 & 0 \\\\\n",
    "0 & 7 & 5 & 3 & 0 \\\\\n",
    "0 & 9 & 4 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "*\\begin{pmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "=\\begin{pmatrix}\n",
    "... & ... & ... \\\\\n",
    "... & 18 & ... \\\\\n",
    "... & ... & ... \\\\\n",
    "\\end{pmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "Now, given the images $I_1 \\in \\mathbb{N}^{5 \\times 5}$, $I_2 \\in \\mathbb{N}^{5 \\times 5}$, and the kernel $g \\in \\mathbb{N}^{2 \\times 2}$, apply the additivity property for one convolution operation: you should expect that $T[I_1 + I_2]$ and $T[I_1 + I_2]$ get the same result.\n",
    "Displaying explicitly the operations you performed, feel free to choose the coordinates to apply the convolution on as you like them.\n",
    "\n",
    "\\begin{equation}\n",
    "    I_1 =\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 6 & 9 & 8 & 0 \\\\\n",
    "        0 & 4 & 8 & 0 & 0 \\\\\n",
    "        0 & 0 & 0 & 1 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix}, \\quad\n",
    "    I_2 =\n",
    "    \\begin{pmatrix}\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "        0 & 6 & 4 & 3 & 0 \\\\\n",
    "        0 & 4 & 0 & 5 & 0 \\\\\n",
    "        0 & 4 & 8 & 8 & 0 \\\\\n",
    "        0 & 0 & 0 & 0 & 0 \\\\\n",
    "    \\end{pmatrix}, \\quad\n",
    "    g =\n",
    "    \\begin{pmatrix}\n",
    "        -1 & 1 \\\\\n",
    "        -1 & 1 \\\\\n",
    "    \\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "Write it in Markdown, you are encouraged to take a look at the cells in this notebook.\n",
    "You can find a cheat sheet [here](https://www.markdownguide.org/basic-syntax)\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV8bL4SjdfRa"
   },
   "source": [
    "#### **Question 1.1: 1D Filters *(3/9 Points)***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSlOA3LdwQX-"
   },
   "source": [
    "##### **1.1.1: 1-D Gaussian Filter**\n",
    "\n",
    "Implement a method which computes the values of a 1-D Gaussian $G_x$ for a given standard deviation $\\sigma$ and filter size $k$.:\n",
    "\\begin{equation}\n",
    "G(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "The method should return a vector $x$ of values on which the Gaussian filter is defined: integer values on the interval $\\left[-k\\sigma,k\\sigma\\right]$.\n",
    "\n",
    "With $\\sigma=3$ and $k=3$ you should get the following output:\n",
    "\n",
    "![](./images/1gauss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(sigma: int, filter_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the Gaussian filter.\n",
    "\n",
    "    Args:\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size, be wary that it is the full size of the filter.\n",
    "\n",
    "    Returns:\n",
    "        Gx (np.ndarray): Gaussian filter.\n",
    "        x (np.ndarray): Array of integer values.\n",
    "    \"\"\"\n",
    "    # Create an array of integer values from -k*sigma to k*sigma\n",
    "    x = np.arange(-( filter_size // 2) * sigma, (filter_size // 2) * sigma + 1)\n",
    "\n",
    "    # Calculate the Gaussian filter values using the formula\n",
    "    Gx = 1 / (np.sqrt(2 * np.pi) * sigma) * np.exp(-0.5 * (x**2) / (sigma**2))\n",
    "\n",
    "    return Gx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-kKAa3iRk_d"
   },
   "source": [
    "--------------------------------------------\n",
    "\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "filter_size = 6\n",
    "Gx, x = gauss(sigma, filter_size)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Gx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variation of $\\sigma$ and filter size**\n",
    "\n",
    "Now we generate a signal and apply the Gauss filter with different values of $\\sigma$ and filter size.\n",
    "Write down your considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xVGsb0X6S9mx",
    "outputId": "06ed9267-54c6-485d-da17-fe49ba90615c"
   },
   "outputs": [],
   "source": [
    "# Generate a noisy signal with increased noise (example data)\n",
    "t = np.linspace(0, 2 * np.pi, 1000)\n",
    "noisy_signal = np.sin(t) + 1.0 * np.random.randn(len(t))  # Increased noise\n",
    "\n",
    "# Define a fixed sigma value\n",
    "sigma = 1.0\n",
    "\n",
    "# Define a range of filter sizes to test\n",
    "filter_sizes = [3, 7]\n",
    "\n",
    "# Create subplots to compare the denoising results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(filter_sizes)):\n",
    "    # Get the Gaussian kernel and x values from the custom gauss function\n",
    "    Gx, x = gauss(sigma, filter_sizes[i])\n",
    "\n",
    "    # Convolve the noisy signal with the Gaussian filter\n",
    "    denoised_signal = np.convolve(noisy_signal, Gx, mode=\"same\")\n",
    "\n",
    "    # Plot the noisy and denoised signals for the current filter_size\n",
    "    plt.subplot(len(filter_sizes), 1, i + 1)\n",
    "    plt.plot(t, noisy_signal, label=\"Noisy Signal\")\n",
    "    plt.plot(t, denoised_signal, label=f\"Denoised (Filter Size {filter_sizes[i]})\")\n",
    "    plt.title(f\"Effect of Filter Size on Denoising (Sigma={sigma})\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define a fixed sigma value\n",
    "sigma = [3, 10]\n",
    "\n",
    "# Define a range of filter sizes to test\n",
    "filter_sizes = 3\n",
    "\n",
    "# Create subplots to compare the denoising results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(len(sigma)):\n",
    "    # Get the Gaussian kernel and x values from the custom gauss function\n",
    "    Gx, x = gauss(sigma[i], filter_sizes)\n",
    "    denoised_signal = np.convolve(noisy_signal, Gx, mode=\"same\")\n",
    "\n",
    "    # Plot the noisy and denoised signals for the current filter_size\n",
    "    plt.subplot(len(sigma), 1, i + 1)\n",
    "    plt.plot(t, noisy_signal, label=\"Noisy Signal\")\n",
    "    plt.plot(t, denoised_signal, label=f\"Denoised (Sigma {sigma[i]})\")\n",
    "    plt.title(f\"Effect of Sigma on Denoising (Filter Size={filter_sizes})\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RjULnuwCzdi",
    "tags": []
   },
   "source": [
    "##### **1-D Box Filter**\n",
    "\n",
    "Implement a method that computes the values of a 1-D Box $B_x$ for a given standard deviation $\\sigma$:\n",
    "\\begin{equation}\n",
    "B= \\left[\\frac{1}{n},\\frac{1}{n},\\dots,\\frac{1}{n}\\right] \\in \\mathbb{R}^n\n",
    "\\end{equation}\n",
    "\n",
    "The method should also return a vector $x$ of values on which the filter is defined: integer values in the interval $\\left[-3\\sigma,3\\sigma\\right]$.\n",
    "\n",
    "An example of a Box Filter:\n",
    "\n",
    "![](./images/1box.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Etp6_6cD45Au"
   },
   "outputs": [],
   "source": [
    "def box(filter_size: int = 3) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Box filter.\n",
    "\n",
    "    Args:\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        Bx (np.ndarray): Box filter.\n",
    "        x (np.ndarray): x values.\n",
    "    \"\"\"\n",
    "    # Create an array of integer values of length = filter_size\n",
    "    x = np.arange(- filter_size // 2, (filter_size // 2))\n",
    "\n",
    "    # Calculate the 1-D Boxer Filter values using the formula\n",
    "    Bx = [1 / len(x)] * len(x)\n",
    "\n",
    "    return Bx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5l08rA310JB"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLkOXmBqdlvg"
   },
   "outputs": [],
   "source": [
    "## function box\n",
    "size = 3\n",
    "Bx, x = box(size)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Bx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHi9bcZWD1s5"
   },
   "source": [
    "##### **1.1.2: 1D Laplacian filter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-WfG0n0UHUb"
   },
   "source": [
    "Derive the 1-D Laplacian $L_x$, then implement a method that computes it for a given standard deviation $\\sigma$ and filter size $k$:\n",
    "\n",
    "With $\\sigma=3$ and $k=10$ you shouls expect the following output:\n",
    "\n",
    "![](./images/1laplace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "Straight answers not showing the derivation steps will not be accepted.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dG(x)}{dx}= \\frac{1}{\\sqrt{2 \\pi \\sigma ^ 2}} {\\mathrm{e}^{-\\frac{{x^2}}{{2\\sigma^2}}}} \\cdot ( - \\frac{1}{2} \\cdot \\sigma ^ 2 \\cdot 2x ) = - \\frac{x}{\\sigma ^ 2 \\sqrt{2 \\pi \\sigma ^ 2}} {\\mathrm{e}^{-\\frac{{x^2}}{{2\\sigma^2}}}} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dG^2(x)}{dx^2} = - \\frac{1}{\\sigma ^ 2 \\sqrt{2 \\pi \\sigma ^ 2}} ({\\mathrm{e}^{-\\frac{{x^2}}{{2\\sigma^2}}}} + x \\cdot {\\mathrm{e}^{-\\frac{{x^2}}{{2\\sigma^2}}}} \\cdot (- \\frac{1}{2 \\sigma ^ 2} \\cdot x)) =  \\dfrac{x^2\\mathrm{e}^{-\\frac{x^2}{2\\sigma^2}}}{\\sqrt{2}\\sqrt{{\\pi}}\\,\\sigma^4\\sigma}-\\dfrac{\\mathrm{e}^{-\\frac{x^2}{2\\sigma^2}}}{\\sqrt{2}\\sqrt{{\\pi}}\\,\\sigma^2\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMRPN2cMF_lp"
   },
   "outputs": [],
   "source": [
    "def laplace(sigma: int, filter_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Laplace 1D filter.\n",
    "\n",
    "    Args:\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        Lx (np.ndarray): Laplace filter.\n",
    "        x (np.ndarray): x values.\n",
    "    \"\"\"\n",
    "    # Create an array of integer values from -k*sigma to k*sigma with length = filter_size\n",
    "    x = np.arange(- sigma * filter_size, sigma * filter_size + 1)\n",
    "\n",
    "\n",
    "    # Calculate the Gaussian filter values using the formula calculated above\n",
    "    num_1 = (x ** 2) * ( np.exp(- (x ** 2) / (2 * ( sigma **2))) )\n",
    "    den_1 = np.sqrt(2 * np.pi ) * ( sigma ** 5 )\n",
    "    num_2 = ( np.exp(- (x ** 2) / (2 * ( sigma **2))) )\n",
    "    den_2 = np.sqrt(2 * np.pi ) * ( sigma ** 3 )\n",
    "    Lx = ( num_1 / den_1 ) - ( num_2 / den_2)\n",
    "\n",
    "    return Lx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HT1d8f_45Ax"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKkIU69UWLvi"
   },
   "outputs": [],
   "source": [
    "sigma = 3\n",
    "filter_size = 10\n",
    "Lx, x = laplace(sigma, filter_size)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Lx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rW8L49XsRmY"
   },
   "source": [
    "#### **1.1.3: An example of non-linear filter: 1-D median filter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfc2oyE2sRmY"
   },
   "source": [
    "Up until now we have worked with linear 1-D filters, you are now asked to implement a non-linear one: the 1-D median filter. \n",
    "At each position $p$ of a given 1-D signal $\\mathcal{S}$, the median filter of size $s$ takes the neighborhood $\\mathcal{N}_s(p)=[\\mathcal{S}(p - \\frac{s - 1}{2}), \\mathcal{S}(p + \\frac{s - 1}{2})]$, and replaces the value of $p$ with the median of the values in $\\mathcal{N}_s(p)$.\n",
    "Since it removes outliers from $\\mathcal{N}_s(p)$, the median filter is often used in image and signal processing to remove noise.\n",
    "\n",
    "Complete the method below to compute the median filter $m(\\cdot)$ of size $s$ for all elements of a signal $\\mathcal{S}$.\n",
    "The method should return the filtered signal.\n",
    "From the description above, you may have noticed that one must *carefully* consider how to deal with the boundaries of the signal.\n",
    "In this exercise, you are free to choose the strategy to deal with the boundaries, you may look [here](https://en.wikipedia.org/wiki/Median_filter).\n",
    "\n",
    "You should get the following input-output pair:\n",
    "\n",
    "![1dmedian](./images/1dmedian.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPx43DPZsRmY"
   },
   "outputs": [],
   "source": [
    "def median_filter(signal: np.ndarray, filter_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Median 1D filter.\n",
    "    You are free to choose how to deal with the beginning and the end of the signal.\n",
    "    You can use the `np.median` function https://numpy.org/doc/stable/reference/generated/numpy.median.html\n",
    "\n",
    "    Args:\n",
    "        signal (np.ndarray): 1-D array of values\n",
    "        filter_size (int): size of the filter\n",
    "\n",
    "    Returns:\n",
    "        signal (np.ndarray): 1-D array of values with the median values computed at each position\n",
    "    \"\"\"\n",
    "    \n",
    "    f=int((filter_size-1)/2)\n",
    "    N=len(signal)\n",
    "    for pos in range(N):\n",
    "        r=np.ndarray(0)\n",
    "        if pos<f:\n",
    "            r=np.append(r,np.repeat(signal[0],f))\n",
    "            r=np.append(r,signal[pos:f+1])         \n",
    "        elif pos>N-f-1:\n",
    "            r=np.append(r,signal[pos-f:N])\n",
    "            r=np.append(r,np.repeat(signal[N-1],f))        \n",
    "        else:\n",
    "            r=np.append(r,signal[pos-f:pos+f+1])       \n",
    "        signal[pos]=np.median(r)\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6ptXOjhsRmZ"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EidbGBWBsRma"
   },
   "outputs": [],
   "source": [
    "filter_size = 3\n",
    "signal = lambda x: 2 * np.sin(x) + np.sin(3 * x) + 0.5 * np.sin(7 * x)\n",
    "x = np.linspace(0, 50, 200)\n",
    "in_signal = signal(x)\n",
    "out_signal = median_filter(in_signal.copy(), filter_size)\n",
    "fig, axs = plt.subplots(2)\n",
    "fig.suptitle(\"Median filter\")\n",
    "axs[0].plot(x, in_signal, \".-\", label=\"$\\mathcal{S}$\", color=\"blue\")\n",
    "axs[0].grid()\n",
    "axs[0].legend()\n",
    "axs[1].plot(x, out_signal, \".-\", label=\"$m(\\mathcal{S})$\", color=\"red\")\n",
    "axs[1].grid()\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUdSP2qtsRma"
   },
   "source": [
    "#### **1.1.4: Check linearity of the filters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYFHymiYsRma"
   },
   "source": [
    "In *Question 1.0: warmup* we have seen some of the properties of linear operators and we have proven the additivity property of convolution. \n",
    "Consider the 1-D Gaussian filter $g(\\cdot)$, the 1-D Laplacian filter $l(\\cdot)$, and the 1-D median filter $m(\\cdot)$. \n",
    "You are given signals $\\mathcal{S}_1$ and $\\mathcal{S}_2$, by taking advantage of the functions you have implemented in the previous exercises, empirically verify the following:\n",
    "\n",
    "1. $g(\\mathcal{S}_1 + \\mathcal{S}_2) = g(\\mathcal{S}_1) + g(\\mathcal{S}_2)$\n",
    "2. $l(\\mathcal{S}_1 + \\mathcal{S}_2) = l(\\mathcal{S}_1) + l(\\mathcal{S}_2)$\n",
    "3. $g(l(\\mathcal{S}_1 + \\mathcal{S}_2)) = (g * l) * \\mathcal{S}_1 + (g * l) * \\mathcal{S}_2$\n",
    "4. $m(\\mathcal{S}_1 + \\mathcal{S}_2) \\neq m(\\mathcal{S}_1) + m(\\mathcal{S}_2)$\n",
    "\n",
    "Can you explain why the median filter is not linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGn5jZHosRma"
   },
   "source": [
    "*HINT: you can exploit the function `convolve` from `scipy.signal` to compute the convolution with the Gaussian and the Laplacian filters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCp0jwLcsRma"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 50, 200)\n",
    "s1 = 2 * np.sin(x) + np.sin(3 * x) + 0.5 * np.sin(7 * x)\n",
    "s2 = 2 * np.cos(x) + np.cos(3 * x) + 0.5 * np.cos(7 * x)\n",
    "sigma, filter_size = 5, 3\n",
    "\n",
    "def gauss2(sigma: int, filter_size: int,s) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    x = np.linspace(0, 50, 200)\n",
    "    Gx = 1 / (np.sqrt(2 * np.pi) * sigma) * np.exp(-0.5 * (x**2) / (sigma**2))\n",
    "    s_filtrato=np.convolve(s,Gx,\"same\")\n",
    "    return s_filtrato\n",
    "\n",
    "\n",
    "g_s1_s2 = gauss2(sigma,filter_size,s1+s2)\n",
    "g_s1_g_s2 = gauss2(sigma,filter_size,s1)+gauss2(5,3,s2)\n",
    "\n",
    "\n",
    "def laplace2(sigma: int, filter_size: int,s) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    x = np.linspace(0, 50, 200) \n",
    "    num_1 = (x ** 2) * ( np.exp(- (x ** 2) / (2 * ( sigma **2))) )\n",
    "    den_1 = np.sqrt(2 * np.pi ) * ( sigma ** 5 )\n",
    "    num_2 = ( np.exp(- (x ** 2) / (2 * ( sigma **2))) )\n",
    "    den_2 = np.sqrt(2 * np.pi ) * ( sigma ** 3 )\n",
    "    Lx = ( num_1 / den_1 ) - ( num_2 / den_2)\n",
    "    s_filtrato=np.convolve(s,Lx,\"same\")\n",
    "    return s_filtrato\n",
    "\n",
    "\n",
    "l_s1_s2  = laplace2(sigma,filter_size,s1+s2)\n",
    "l_s1_l_s2 =laplace2(sigma,filter_size,s1)+laplace2(5,3,s2)\n",
    "\n",
    "\n",
    "\n",
    "g_l_s1_s2 = gauss2(sigma,filter_size,laplace2(sigma,filter_size,s1+s2))\n",
    "g_l_s1_g_l_s2 = gauss2(sigma,filter_size,laplace2(sigma,filter_size,s1))+gauss2(sigma,filter_size,laplace2(sigma,filter_size,s2))\n",
    "\n",
    "\n",
    "\n",
    "m_s1_s2 = \"YOUR CODE FOR THE FIRST TERM OF EQ.4\"\n",
    "m_s1_m_s2 = \"YOUR CODE FOR THE SECOND TERM OF EQ.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqzlGFQWsRma"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr2O8w1psRma"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(g_s1_s2, g_s1_g_s2), \"Equation (1) is not verified\"\n",
    "assert np.allclose(l_s1_s2, l_s1_l_s2), \"Equation (2) is not verified\"\n",
    "assert np.allclose(g_l_s1_s2, g_l_s1_g_l_s2), \"Equation (3) is not verified\"\n",
    "assert ~np.allclose(m_s1_s2, m_s1_m_s2), \"Equation (4) is not verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnGr9_QEsRmb"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1)\n",
    "fig.suptitle(\"Check linearity of the filters\")\n",
    "ys = [\n",
    "    s1,\n",
    "    s2,\n",
    "    g_s1_s2,\n",
    "    g_s1_g_s2,\n",
    "    l_s1_s2,\n",
    "    l_s1_l_s2,\n",
    "    g_l_s1_s2,\n",
    "    g_l_s1_g_l_s2,\n",
    "    m_s1_s2,\n",
    "    m_s1_m_s2,\n",
    "]\n",
    "labels = [\n",
    "    \"$\\mathcal{S}_1$\",\n",
    "    \"$\\mathcal{S}_2$\",\n",
    "    \"$g(\\mathcal{S}_1 + \\mathcal{S}_2)$\",\n",
    "    \"$g(\\mathcal{S}_1) + g(\\mathcal{S}_2)$\",\n",
    "    \"$l(\\mathcal{S}_1 + \\mathcal{S}_2)$\",\n",
    "    \"$l(\\mathcal{S}_1) + l(\\mathcal{S}_2)$\",\n",
    "    \"$g(l(\\mathcal{S}_1 + \\mathcal{S}_2))$\",\n",
    "    \"$(g * l) * \\mathcal{S}_1 + (g * l) * \\mathcal{S}_2$\",\n",
    "    \"$m(\\mathcal{S}_1 + \\mathcal{S}_2)$\",\n",
    "    \"$m(\\mathcal{S}_1) + m(\\mathcal{S}_2)$\",\n",
    "]\n",
    "colors = [\n",
    "    \"blue\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"gray\",\n",
    "    \"purple\",\n",
    "    \"gray\",\n",
    "    \"orchid\",\n",
    "    \"gray\",\n",
    "    \"orange\",\n",
    "    \"gray\",\n",
    "]\n",
    "for y_idx in range(0, len(ys), 2):\n",
    "    i = y_idx // 2\n",
    "    axs[i].plot(x, ys[y_idx], \".-\", label=labels[y_idx], color=colors[y_idx])\n",
    "    axs[i].plot(\n",
    "        x, ys[y_idx + 1], \"--\", label=labels[y_idx + 1], color=colors[y_idx + 1]\n",
    "    )\n",
    "    axs[i].grid()\n",
    "    axs[i].legend(loc=\"upper right\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6BSqihaC1fp"
   },
   "source": [
    "#### **Question 1.2: 2D Filters *(4/9 Points)***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXmgnhsShOHB",
    "tags": []
   },
   "source": [
    "##### **2-D Laplacian filter**\n",
    "\n",
    "The function should take an image as input and return the result of the convolution of the image with a 2-D Laplacian kernel.\n",
    "You can use Python’s `convolve2D` function if you don’t want to implement it yourself - it hase been aliased as `conv2` and `convolve`.\n",
    "\n",
    "See the figure below for an illustration of Laplacian filtering.\n",
    "\n",
    "![](./images/stella_laplace.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tncxK4D4cpfA",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def laplacefiltering2D(img: np.ndarray, sigma: int, filter_size: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Laplacian filter.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        smooth_img (np.ndarray): Smoothed image.\n",
    "    \"\"\"\n",
    "    # Create a 1-D Laplace Filter\n",
    "    laplace_filter_1d = laplace(sigma, filter_size)\n",
    "    \n",
    "    laplace_filter_2d = np.outer(laplace_filter_1d, laplace_filter_1d)  \n",
    "\n",
    "    # Apply the convolution to the original image\n",
    "    smooth_img = conv2(img, laplace_filter_2d)\n",
    "\n",
    "    return smooth_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaRGkjLI4peV"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "Ab-ERNGMD7aX",
    "outputId": "e796d020-82ed-407d-c3ba-807e542e3afa"
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"./images/stella.jpg\")))\n",
    "smooth_img = laplacefiltering2D(img, 3)\n",
    "\n",
    "imgs = [img, smooth_img]\n",
    "labels = [\"Input Image\", \"Laplacian Filtered Image\"]\n",
    "\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=2, cmap=\"gray\", vmin=None, vmax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv-Fw9VjDwzc",
    "tags": []
   },
   "source": [
    "##### **2-D Box filter**\n",
    "\n",
    "The function should take an image as input and return the result of the convolution of this image with a 2D Box kernel.\n",
    "Beware of errors in the following code, find them, and correct them.\n",
    "You will be provided with the image to which the correct box filter has already been applied and you can use the SSIM metric to check that your result is correct, $SSIM = 1$ means that it is correct.\n",
    "\n",
    "See the figure below for an illustration of Box filtering.\n",
    "\n",
    "![](./images/box_image.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTYJh1IPdpog"
   },
   "outputs": [],
   "source": [
    "def boxfiltering(img: np.ndarray, filter_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Box filter, leveraging the previous box.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        smooth_img (np.ndarray): Smoothed image.\n",
    "    \"\"\"\n",
    "    kernel, _ = box(filter_size)\n",
    "\n",
    "    # Compute Gaussian on rows\n",
    "    partial = np.apply_along_axis(convolve, 1, img, kernel, mode=\"same\")\n",
    "\n",
    "    # Compute Gaussian on columns\n",
    "    smooth_img = np.apply_along_axis(convolve, 0, partial, kernel, mode=\"same\") ### columns means parameter axis = 0 NOT 1 (first error)\n",
    "\n",
    "    return np.array(smooth_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GP37W6D5PHZ"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iRbG_ZGtihrP",
    "outputId": "03ef20e1-318a-4e74-a8f2-9edfb9261c9e"
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"./images/stella.jpg\")))\n",
    "smooth_img = np.load(\"assets/box_filter.npy\")\n",
    "smooth_fooled = boxfiltering(img, 20)\n",
    "\n",
    "\n",
    "imgs = [img, smooth_img, smooth_fooled]\n",
    "labels = [\"Input Image\", \"Box Filtered Image\", \"Box Filtered Image (Fooled)\"]\n",
    "\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=None, vmax=None)\n",
    "\n",
    "print(\n",
    "    f\"real_ssim_score:\\t{ssim(smooth_img, smooth_img, data_range=smooth_img.max() - smooth_img.min())}\\nyour_ssim_score:\\t{ssim(smooth_img, smooth_fooled, data_range=smooth_img.max() - smooth_img.min())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42Ywq00_XYYJ"
   },
   "source": [
    "\n",
    "##### **Separability and computational efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_V4mCuopsRmd"
   },
   "source": [
    "Analitically prove that the Laplacian filter is separable.\n",
    "Recall that the Laplacian operator is defined as $\\nabla^2 = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lu8ctnbdLjOb"
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J75hCepmbmeD"
   },
   "source": [
    "Briefly explain why it is more convenient computationally speaking to use two 1D Laplacian filters rather than one 2D Laplacian filter.\n",
    "Assume that the dimension of the 2D Laplacian filter is $k^2$ and that the dimension of the two 1D Laplacian filters is $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0Ky9veh2W7_"
   },
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGqZbBfzdZ75"
   },
   "source": [
    "##### **Practical example of separability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmEEOUT_20xl"
   },
   "source": [
    "Up to this point, we have seen that both the Gaussian and the Laplacian operators are linear and you have explicitly proven that the Laplacian operator is separable. \n",
    "As you may guess, the Gaussian operator is also separable, and so is the composition of them: the Laplacian of Gaussian (LoG) operator. \n",
    "Recall from section section \"2-D Laplacian filter\" that the LoG operator is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla^2 \\circ G = \\frac{d^2G(x)}{dx^2}=-\\frac{\\sigma^2 - x^2}{\\sqrt{2\\pi}\\sigma^5}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Previously, you have implemented a 2-D LoG filter without leveraging the separability property.\n",
    "In this section, you're asked to implement again the 2-D LoG filter **exploiting the separability**, i.e. convolving the image with a separable 1-D Laplacian kernel along axes.\n",
    "\n",
    "Compare the images to check that the separability property is valid. Note that the last image shows the differences between the separable case and the non separable case: it should be black up to numerical approximations, i.e. it should cointain approximately 0 everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOrXeEJn2hSr"
   },
   "outputs": [],
   "source": [
    "def laplacefiltering(img: np.ndarray, sigma: int, filter_size: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Laplacian filter, leveraging the previous laplacian and the separability property.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        sigma (int): Standard deviation.\n",
    "        filter_size (int): Filter size.\n",
    "\n",
    "    Returns:\n",
    "        derived_img (np.ndarray): Derived image.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return derived_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orKF4ubm7CiG"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBNm7lHpbSEn"
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/stella.jpg\")))\n",
    "derived_img_separable = laplacefiltering(img, sigma=3)\n",
    "derived_img_non_separable = laplacefiltering2D(img, sigma=3)\n",
    "difference_img = derived_img_separable - derived_img_non_separable\n",
    "\n",
    "plt.figure(2)\n",
    "ax1 = plt.subplot(1, 4, 1)\n",
    "ax1.set_xlabel(\"Input Image\")\n",
    "ax2 = plt.subplot(1, 4, 2)\n",
    "ax2.set_xlabel(\"Laplacian Filtered Image (separable case)\")\n",
    "ax3 = plt.subplot(1, 4, 3)\n",
    "ax3.set_xlabel(\"Laplacian Filtered Image\")\n",
    "ax4 = plt.subplot(1, 4, 4)\n",
    "ax4.set_xlabel(\"Difference image (separable - non separable)\")\n",
    "\n",
    "\n",
    "plt.sca(ax1)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.sca(ax2)\n",
    "plt.imshow(derived_img_separable, cmap=\"gray\")\n",
    "plt.sca(ax3)\n",
    "plt.imshow(derived_img_non_separable, cmap=\"gray\")\n",
    "plt.sca(ax4)\n",
    "plt.imshow(difference_img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgiRrMnf7AfJ"
   },
   "source": [
    "##### **Gaussian Blur Filter**\n",
    "\n",
    "Implement a 2D Gaussian filter.\n",
    "\n",
    "See the figure below for an illustration of the sharpening filter:\n",
    "\n",
    "![](./images/moon_gauss.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gDNiZIO2sj_"
   },
   "outputs": [],
   "source": [
    "def gaussfiltering(img: np.ndarray, sigma: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 2D Gaussian filter, leveraging the previous gauss.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        sigma (int): Standard deviation.\n",
    "\n",
    "    Returns:\n",
    "        smooth_img (np.ndarray): Smoothed image.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    \n",
    "    Gx,x = gauss(sigma, filter_size = 6) # Filter_size is not defined before...to get in output the image above you have to put filter_size = 6\n",
    "    GxH = Gx.reshape((1,-1))\n",
    "    GxV = Gx.reshape((-1,1))\n",
    "    smooth_img = conv2(conv2(img, GxH, 'same'), GxV, 'same')\n",
    "\n",
    "    return np.array(smooth_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/moon.jpg\")))\n",
    "imgs = [img, gaussfiltering(img, 5)]\n",
    "labels = [\"Input Image\", \"Gaussian Filtered Image\"]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=2, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrYuF1LHviyW"
   },
   "source": [
    "### **#1 Report *(1/9 Points)***\n",
    "\n",
    "Use the images from the previous exercises to write a report on what you learned about filters and convolutions **(in the text block below)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ULllx0XsRmg"
   },
   "source": [
    "Write the filter that was used to produce the images.\n",
    "\n",
    "![](./images/report1_ex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr57pQTDYk54"
   },
   "source": [
    "--------------------------------------------\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "- Image A filter ->\n",
    "- Image B filter ->\n",
    "- Image C filter ->\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxbJ5c64lwHn"
   },
   "source": [
    "## **Question 2: Multi-Scale Image Representations** *(9 Points)*\n",
    "\n",
    "Edges represents object boundaries, thus edge detection is a very important preprocessing step for any object detection or recognition process.\n",
    "Simple edge detection kernels are based on approximation of gradient images.\n",
    "\n",
    "You will use some basic edge detection kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3QKyhngPMzp"
   },
   "source": [
    "#### **Question 2.1: Sobel Operator** *(1/9 Points)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCwYNYB-64-x"
   },
   "source": [
    "The Sobel operator is used in image processing, particularly within edge detection algorithms.\n",
    "Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function.\n",
    "\n",
    "See figure below for illustration of Sobel operators in action:\n",
    "\n",
    "![](./images/valve_sobel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lo42CdPoHhMC"
   },
   "outputs": [],
   "source": [
    "def sobel_x(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 3x3 Sobel discrete operator for vertical edges.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        Fx (np.ndarray): Image with vertical edges.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################)\n",
    "\n",
    "    return Fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkJg_B_bHqXJ"
   },
   "outputs": [],
   "source": [
    "def sobel_y(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implement a 3x3 Sobel discrete operator for horizontal edges.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        Fy (np.ndarray): Image with horizontal edges.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return Fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Y6VvgGn9VG5"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JLhOfF_lwUd",
    "outputId": "c579bdca-b160-47ac-8da6-3478cd1432c4"
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/valve.png\")))\n",
    "imgs = [img, sobel_x(img), sobel_y(img)]\n",
    "labels = [\"Input Image\", \"Vertical Edges Detection\", \"Horizontal Edges Detection\"]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SK48Mn9Kgl9w"
   },
   "source": [
    "#### **Question 2.2: Gradient Magnitude** *(1/9 Points)*\n",
    "Using the previously defined functions `sobel_x` and `sobel_y`, retrieve the gradient magnitude of the image.\n",
    "\n",
    "See the figure below for an illustration of the Gradient Magnitude:\n",
    "\n",
    "![](./images/sobel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uL6-KTBGICp3"
   },
   "outputs": [],
   "source": [
    "def gradient_magnitude(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply the Sobel operator to the image and compute the gradient magnitude.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        magnitude (np.ndarray): Gradient magnitude.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0j6hYlS-TiD"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-X8ONF6hpYU",
    "outputId": "d025f2dc-fe67-4c72-bde5-77f2a5777954"
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/valve.png\")))\n",
    "igms = [img, gradient_magnitude(img)]\n",
    "labels = [\"Input Image\", \"Gradient Magnitude\"]\n",
    "plot_pictures(igms, labels, nrows=1, ncols=2, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVVYB2LlW7Jq"
   },
   "source": [
    "#### **Question 2.3 Discrete Laplacian Operator** *(2/9 Points)*\n",
    "\n",
    "Write the discrete Laplacian filter and given an image $x$, a Gaussian filter $G(x)$ and a discrete Laplacian filter $L(x)$, compute:\n",
    "- $ G(L(x)) $\n",
    "- $ L(G(x)) $\n",
    "Provide a brief explanation of the result obtained.\n",
    "\n",
    "See the figure below for illustration of the discrete Laplacian:\n",
    "\n",
    "![](./images/laplacian.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YL6Y7NbyIsQ9"
   },
   "outputs": [],
   "source": [
    "# from scipy.ndimage import gaussian_filter\n",
    "def discrete_laplace(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Discrete Laplacian operator.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "\n",
    "    Returns:\n",
    "        Lap (np.ndarray): Image after applying the Laplacian operator.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"./images/lenna.jpg\")))\n",
    "sigma = 1.0\n",
    "\n",
    "image_edges = \"YOUR CODE HERE\"\n",
    "image_edges_smoothed = \"YOUR CODE HERE\"\n",
    "\n",
    "image_smoothed = \"YOUR CODE HERE\"\n",
    "image_smoothed_edges = \"YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"./images/lenna.jpg\")))\n",
    "sigma = 1.0\n",
    "\n",
    "image_edges = discrete_laplace(img)\n",
    "image_edges_smoothed = gaussfiltering(image_edges, sigma=sigma)\n",
    "\n",
    "image_smoothed = gaussfiltering(img, sigma=sigma)\n",
    "image_smoothed_edges = discrete_laplace(image_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKbZBjpN_Vrz"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 956
    },
    "id": "5QsyjlxJXlwg",
    "outputId": "2d2d063c-43a0-4ee9-b201-42b525e3c12d"
   },
   "outputs": [],
   "source": [
    "# LoG\n",
    "imgs = [img, image_edges, image_edges_smoothed]\n",
    "labels = [\n",
    "    \"Input Image\",\n",
    "    \"Image with Laplacian Operator\",\n",
    "    \"Image with Laplacian-Gaussian Operator\",\n",
    "]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "# GoL\n",
    "imgs = [img, image_smoothed, image_smoothed_edges]\n",
    "labels = [\n",
    "    \"Input Image\",\n",
    "    \"Image with Gaussian Operator\",\n",
    "    \"Image with Laplacian-Gaussian Operator\",\n",
    "]\n",
    "plot_pictures(imgs, labels, nrows=1, ncols=3, cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"ssim_score =\",\n",
    "    round(\n",
    "        ssim(\n",
    "            image_edges_smoothed,\n",
    "            image_smoothed_edges,\n",
    "            data_range=image_edges_smoothed.max() - image_edges_smoothed.min(),\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNmjvog3-lo7"
   },
   "source": [
    "#### **Question: 2.4 Canny Edge Detector and Template Matching** *(3/9 Points)*\n",
    "The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL8Dr0jtVj2l"
   },
   "source": [
    "The Canny edge detection algorithm is composed of 5 steps:\n",
    "\n",
    "1. Noise reduction: apply Gaussian filter to smooth the image in order to remove the noise\n",
    "2. Gradient calculation: find the intensity gradients of the image\n",
    "3. Non-maximum suppression: apply gradient magnitude thresholding or lower bound cut-off suppression to get rid of spurious response to edge detection\n",
    "4. Double threshold: apply double threshold to determine potential edges\n",
    "5. Edge Tracking by Hysteresis: track edge by hysteresis: finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.\n",
    "\n",
    "\n",
    "You can learn more about the Canny edge detector at the following links:\n",
    "- [Canny Edge Detection](https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html).\n",
    "- [Canny Edge Detection Step by Step in Python — Computer Vision](https://towardsdatascience.com/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123).\n",
    "- [What is a Canny Edge Detection Algorithm?](https://towardsai.net/p/computer-vision/what-is-a-canny-edge-detection-algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoeKXX9zJbhv"
   },
   "source": [
    "##### **Stage 1** - *Noise reduction*\n",
    "\n",
    "Apply Gaussian filter to smooth the image in order to remove the noise. \n",
    "**You just need to run the code for this stage**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_T3xEpqsvHpT"
   },
   "outputs": [],
   "source": [
    "# STEP 1:\n",
    "img = rgb2gray(np.array(Image.open(\"images/escher_circle.jpg\")))\n",
    "smoothed_img = gaussfiltering(img, sigma=1)\n",
    "\n",
    "plot_pictures([img, smoothed_img], [\"Input image\", \"Smoothed image\"], 1, 2, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y17e-E0YJk8B"
   },
   "source": [
    "##### **Stage 2** - *Gradient calculation*\n",
    "\n",
    "This step detects edges intensity and direction by calculating the gradient of the image through edge detection operators.\n",
    "\n",
    "Edges correspond to a change of pixels’ intensity, the easiest way to detect it is applying filters that highlight it in both directions: horizontal ($x$) and vertical ($y$).\n",
    "\n",
    "When the image is smoothed, the derivatives $D_x(I)$ and $D_y(I)$ w.r.t. $x$ and $y$ are calculated. \n",
    "It can be implemented by convolving $I$ with Sobel kernels $K_x$ and $K_y$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking advantage of the functions `sobel_x` and `sobel_y` you have previously implemented, compute the gradient magnitude and direction of the image.\n",
    "Your function will output the magnitude $G$ and the slope $\\theta$ of the gradient. \n",
    "Scale the magnitude to the range $[0,255]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gCm5wsPwMcU"
   },
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "def sobel_filters(img: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function applies the sobel filter to the input image in x and y direction.\n",
    "    Scale the magnitude to [0, 255] and return the magnitude and the direction of the gradient.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "\n",
    "    Returns:\n",
    "        G (np.ndarray): gradient magnitude\n",
    "        theta (np.ndarray): gradient direction\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return (G, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImXJa-NFwiP6"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yltXctlpV85I"
   },
   "outputs": [],
   "source": [
    "G, theta = sobel_filters(smoothed_img)\n",
    "\n",
    "plot_pictures([G, theta], [\"Gradient magnitude\", \"Gradient direction\"], 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsXpAOIGJqTv"
   },
   "source": [
    "##### **Stage 3** - *Non-maximum suppression*\n",
    "\n",
    "The image is scanned along the image gradient direction and, if pixels are not part of the local maxima, they are set to zero. \n",
    "This has the effect of suppressing all image information that is not part of local maxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(img: np.ndarray, D: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function performs non-maximum suppression on the input image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "        D (np.ndarray): gradient direction\n",
    "\n",
    "    Returns:\n",
    "        Z (np.ndarray): image after non-maximum suppression\n",
    "    \"\"\"\n",
    "\n",
    "    M, N = img.shape\n",
    "    Z = np.zeros((M, N), dtype=np.uint8)\n",
    "    PI = 180\n",
    "    angle = (np.rad2deg(D) + PI) % PI\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return (Z / Z.max() * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VXiHkOXV88D"
   },
   "outputs": [],
   "source": [
    "Z = non_max_suppression(G, theta)\n",
    "\n",
    "plot_pictures(\n",
    "    [G, Z],\n",
    "    [\"Gradient magnitude\", \"Non-max suppressed magnitude\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LCeVFVuJw8W"
   },
   "source": [
    "##### **Stage 4** - *Thresholding*\n",
    "\n",
    "After application of non-maximum suppression, remaining edge pixels provide a more accurate representation of real edges in an image. \n",
    "However, some edge pixels remain that are caused by noise and color variation. \n",
    "To account for these spurious responses, it is essential to filter out edge pixels with a weak gradient value and preserve edge pixels with a high gradient value. \n",
    "\n",
    "This is accomplished by selecting high and low threshold values: \n",
    "- If an edge pixel’s gradient value is higher than the high threshold value, it is marked as a strong edge pixel.\n",
    "- If an edge pixel’s gradient value is smaller than the high threshold value and larger than the low threshold value, it is marked as a weak edge pixel. \n",
    "- If an edge pixel's gradient value is smaller than the low threshold value, it will be suppressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `threshold` that takes as input the image, the low and high threshold ratios and returns a tuple whose elements are the thresholded image, the value of the weak edges and the value of the strong edges. Set the value of weak edges to 100 and the value of strong edges to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "def threshold(\n",
    "    img: np.ndarray, low_threshold: int = 100, high_threshold: int = 200\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function applies a double thresholding to the input image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "        low_threshold (int): low threshold\n",
    "        high_threshold (int): high threshold\n",
    "\n",
    "    Returns:\n",
    "        res (np.ndarray): thresholded image\n",
    "    \"\"\"\n",
    "\n",
    "    i_height, i_width = img.shape\n",
    "    res = np.zeros((i_height, i_width), dtype=np.uint8)\n",
    "    weak, strong = 100, 255\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return (res, weak, strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiiKNUJRzG2h"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAc7HBZD-cgs"
   },
   "outputs": [],
   "source": [
    "res, weak, strong = threshold(Z, low_threshold=25, high_threshold=50)\n",
    "\n",
    "plot_pictures(\n",
    "    [Z, res],\n",
    "    [\"Non-max suppressed magnitude\", \"Double-thresholded magnitude\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWNQzsTYJz_D"
   },
   "source": [
    "##### **Stage 5** - *Hysteresis*\n",
    "\n",
    "Based on the threshold results, the hysteresis consists of transforming weak pixels into strong ones, if and only if at least one of the pixels around the one being processed is a strong one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar2KDJx90dA3"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btBOzWyGzndT"
   },
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "def hysteresis(img: np.ndarray, weak: int, strong: int = 255) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function applies hysteresis to the input image.\n",
    "\n",
    "    Args:\n",
    "        img (np.mdarray): input image.\n",
    "        weak (int): weak threshold.\n",
    "        strong (int): strong threshold.\n",
    "\n",
    "    Returns:\n",
    "        img (np.ndarray): image after hysteresis.\n",
    "    \"\"\"\n",
    "    M, N = img.shape\n",
    "    img_ = img.copy()\n",
    "    strong_edges_idxs = np.argwhere(img == strong).tolist()\n",
    "    while len(strong_edges_idxs) > 0:\n",
    "        i, j = strong_edges_idxs.pop()\n",
    "        if (i - 1 >= 0) and (j - 1 >= 0) and (i + 1 < M) and (j + 1 < N):\n",
    "            weak_edges_mask = img_[i - 1 : i + 2, j - 1 : j + 2] == weak\n",
    "            if np.any(weak_edges_mask):\n",
    "                img_[i - 1 : i + 2, j - 1 : j + 2][weak_edges_mask] = strong\n",
    "                weak_edges_idxs = (\n",
    "                    (np.argwhere(weak_edges_mask) - 1) + np.array([i, j])\n",
    "                ).tolist()\n",
    "                strong_edges_idxs = strong_edges_idxs + weak_edges_idxs[::-1]\n",
    "    img_[img_ != strong] = 0\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0yl_mSWuYL4Y"
   },
   "outputs": [],
   "source": [
    "final_img = hysteresis(res, weak=weak)\n",
    "\n",
    "plot_pictures(\n",
    "    [res, final_img],\n",
    "    [\"Double-thresholded magnitude\", \"Result after hysteresis\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Wrap up**\n",
    "Once you have seen how the Canny edge detector works step by step, implement the following `canny_edge_detector` function that wraps all the previous steps and returns the final image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detector(\n",
    "    img: np.ndarray, sigma: int = 1, low_threshold: int = 50, high_threshold: int = 100\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function implements the Canny edge detector.\n",
    "    Put together the previous functions to implement the Canny edge detector.\n",
    "    Don't apply the gaussian filter if sigma=0.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image\n",
    "        sigma (int): standard deviation for the gaussian filter; if sigma=0, no gaussian filter is applied\n",
    "        low_threshold (int): low threshold\n",
    "        high_threshold (int): high threshold\n",
    "\n",
    "    Returns:\n",
    "        out_img (np.ndarray): image after applying the Canny edge detector\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = canny_edge_detector(img, sigma=1, low_threshold=25, high_threshold=50)\n",
    "\n",
    "plot_pictures(\n",
    "    [img, out_img],\n",
    "    [\"Input image\", \"Canny edge detector output\"],\n",
    "    1,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2.4.1: Template matching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a template matching algorithm. \n",
    "The goal of template matching is to find the patch in the image that is most similar to a given template. \n",
    "In this exercise, you are going to use the Canny edge detector to extract the edges of the image and the template.\n",
    "Then, you will find the patch in the image that is most similar to the template. To choose the patch, you are asked to implement the *Normalized Sum of Squared Differences (NSSD)* metric:\n",
    "\\begin{equation}\n",
    "    \\mathrm{NSSD}(I_{ij}, T) = \\frac{\\|I_{ij} - T\\|^2}{\\|I_{ij}\\| \\cdot \\|T\\|}\n",
    "\\end{equation}\n",
    "\n",
    "Note that $T$ denotes the template image, $I$ the target image, $I_{ij}$ a patch of $I$ at position $ij$ having the same dimensions of $T$, $I_{ij}^T$ the transpose of a $I_{ij}$.\n",
    "\n",
    "Note also that the more $I_{ij}$ and $T$ are similar, the less the value of $\\mathrm{NSSD}(I_{ij}, T)$.\n",
    "\n",
    "More resources on template matching can be found [here](http://bias.csr.unibo.it/fei/Dispense/6%20-%20FEI%20-%20Template%20Matching.pdf) and [here](https://web.stanford.edu/class/ee368/Handouts/Lectures/2019_Winter/9-TemplateMatching.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following function that takes as input the target image $I$, and the template image $T$. The returned values are a matrix of shape `(i_height-t_heigh, i_width-t_width)` containing the metric scores at each position and the indexes $(i,j)$ of the patch in $I$ with the best metric value, as depicted below. Note that $i$ indexes along the height of $I$, $j$ indexes along the width of $I$.\n",
    "\n",
    "```\n",
    "(i,j)-------width--------+\n",
    "  |                      |\n",
    "  |                      |\n",
    "height                   |\n",
    "  |                      |\n",
    "  |                      |\n",
    "  +----------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_template(\n",
    "    img: np.ndarray, template: np.ndarray\n",
    ") -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    This function implements the template matching algorithm.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image.\n",
    "        template (np.array): template to match.\n",
    "\n",
    "    Returns:\n",
    "        img_score (np.ndarray): metric scores after applying the template matching algorithm.\n",
    "        best_match_idxs (tuple): index of the best match.\n",
    "    \"\"\"\n",
    "\n",
    "    t_height, t_width = template.shape\n",
    "    i_height, i_width = img.shape\n",
    "    assert (i_height >= t_height) and (\n",
    "        i_width >= t_width\n",
    "    ), f\"Cannot match template of shape {template.shape} with image of shape {img.shape}\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return img_score, best_match_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: by running the following code, you should be able to detect the bigger fish.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "img_1 = rgb2gray(np.array(Image.open(\"images/underwater_template.png\")))\n",
    "img_2 = rgb2gray(np.array(Image.open(\"images/underwater.png\")))\n",
    "\n",
    "template = canny_edge_detector(img_1, sigma=1, low_threshold=15, high_threshold=30)\n",
    "target = canny_edge_detector(img_2, sigma=1, low_threshold=15, high_threshold=30)\n",
    "\n",
    "img_score_nssd, best_match_nssd = match_template(target, template)\n",
    "\n",
    "imgs = [img_1, img_2, img_2]\n",
    "xlabels = [\"Template\", \"Target\", \"Normalized SSD\"]\n",
    "axs = plot_pictures(imgs, xlabels, 1, 3, show=False, vmin=None, vmax=None)\n",
    "axs[-1].plot(best_match_nssd[1], best_match_nssd[0], \"ro\")\n",
    "axs[-1].add_patch(\n",
    "    patches.Rectangle(\n",
    "        (best_match_nssd[1], best_match_nssd[0]),\n",
    "        template.shape[1],\n",
    "        template.shape[0],\n",
    "        linewidth=1,\n",
    "        edgecolor=\"r\",\n",
    "        facecolor=\"none\",\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can look at the template and at target image side by side, after having applied the Canny edge detector.\n",
    "Notice how they are different even though the parameters of the Canny edge detector are the same: this is due to the images not having the same background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [template, target]\n",
    "xlabels = [\"Template edges\", \"Target edges\"]\n",
    "plot_pictures(imgs, xlabels, 1, 2, show=True, cmap=\"gray\", same_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWJWsjraqarL"
   },
   "source": [
    "#### **Question: 2.5 Gaussian Pyramid and Multi-Scale Template Matching** *(2/9 Points)*\n",
    "\n",
    "Now let's implement a multi-scale object detection algorithm with Gaussian pyramid and template matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Pyramid**\n",
    "\n",
    "Implement a Gaussian Pyramid:\n",
    "- Write a function for downscaling (you can use [`skimage.transform.resize`](https://scikit-image.org/docs/stable/api/skimage.transform.html#skimage.transform.resize))\n",
    "- Write a function for the Gaussian Pyramid consisting of the following steps:\n",
    "  1. Downscale the image by the input factor.\n",
    "  2. Apply Gaussian filter on the Image to obtain a smoothed image.\n",
    "  <!-- 3. **Apply Laplacian filter** on the smoothed image to obtain edges (you can use [`scipy.ndimage.laplace`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.laplace.html)) -->\n",
    "  4. Plot the 3 images side by side.\n",
    "  5. Repeat previous steps with the resized smoothed version of the image\n",
    "\n",
    "<!-- See figure below for an illlustration of Gaussian Pyramid.\n",
    "![](https://drive.google.com/uc?export=view&id=14RNWwnyg-yS1FUPLCuj2bpxrluKkgjBx) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZfUFGrAMVm2"
   },
   "outputs": [],
   "source": [
    "def downscale(img: np.ndarray, factor: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale the input image by the given factor.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        factor (float): Resizing factor.\n",
    "\n",
    "    Returns:\n",
    "        resized_img (np.ndarray): Resized image.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5WgyQFdMmUC"
   },
   "outputs": [],
   "source": [
    "def GaussianPyramid(img, steps=3, factor=0.5, sigma=4):\n",
    "    \"\"\"\n",
    "    This function implements the Gaussian Pyramid and shows the results.\n",
    "    Leverage the \"downscale\" function.\n",
    "\n",
    "    Inputs:\n",
    "        img: the image\n",
    "        steps: number of steps for the Pyramid\n",
    "        factor: the scaling factor to resize the image at each step\n",
    "        sigma: the Gaussian filter parameter\n",
    "\n",
    "    Outputs:\n",
    "        downscale_l: list of downscale images\n",
    "        blur_l: list of blurred images\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNV0zSLupu3x"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jaHkcIkeUtU"
   },
   "outputs": [],
   "source": [
    "img = rgb2gray(np.array(Image.open(\"images/coffee.jpg\")))\n",
    "downscale_l, blur_l = GaussianPyramid(img, steps=3, factor=0.5, sigma=4)\n",
    "\n",
    "for i in range(len(downscale_l)):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20 // (i + 1), 10 // (i + 1)))\n",
    "    plt.gray()\n",
    "    fig.tight_layout()\n",
    "    axes[0].imshow(downscale_l[i])\n",
    "    axes[0].set_title(f\"Resized image {downscale_l[i].shape}\")\n",
    "    axes[1].imshow(blur_l[i])\n",
    "    axes[1].set_title(f\"Smooth image {blur_l[i].shape}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Scale Object Detection**\n",
    "\n",
    "Write a multi-scale object detection algorithm using the Gaussian Pyramid and the template matching algorithm you have implemented in the previous exercise.\n",
    "\n",
    "You should expect an output image like that\n",
    "\n",
    "![](./images/multi_scale_template_match.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_scale_match_template(\n",
    "    img: np.ndarray,\n",
    "    template: np.ndarray,\n",
    "    steps: int,\n",
    "    factor: float,\n",
    "    sigmas: List[float],\n",
    "    low_thresholds: List[int],\n",
    "    high_thresholds: List[int],\n",
    ") -> List[Dict[str, Union[np.ndarray, Tuple[int, int]]]]:\n",
    "    \"\"\"\n",
    "    This function implements the multi-scale template matching.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image.\n",
    "        template (np.ndarray): template image.\n",
    "        steps (int): number of steps for the Pyramid.\n",
    "        factor (float): the scaling factor to resize the image at each step.\n",
    "        sigmas (List[float]): the Gaussian filter parameter.\n",
    "        low_thresholds (List[int]): low thresholds.\n",
    "        high_thresholds (List[int]): high thresholds.\n",
    "\n",
    "    Returns:\n",
    "        out (list): list of dictionaries containing:\n",
    "            img_score (np.ndarray): score image.\n",
    "            result (tuple): best match coordinates.\n",
    "            template (np.ndarray): template image.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    for i, im in enumerate([template] + downscale_l):\n",
    "        #####################################################\n",
    "        ##                 YOUR CODE HERE                  ##\n",
    "        ##     here we update the variable `template`      ##\n",
    "        #####################################################\n",
    "\n",
    "        out.append({\"img_score\": img_score, \"result\": result, \"template\": template})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Do not write below this line just run it**\n",
    "_____________________________________________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = rgb2gray(np.array(Image.open(\"images/underwater.png\")))\n",
    "img2 = rgb2gray(np.array(Image.open(\"images/underwater_template.png\")))\n",
    "\n",
    "sigmas = [0.5, 0]\n",
    "low_thresholds = [50, 0]\n",
    "high_thresholds = [100, 10]\n",
    "\n",
    "znssd = multi_scale_match_template(\n",
    "    img=img1,\n",
    "    template=img2,\n",
    "    steps=1,\n",
    "    factor=0.5,\n",
    "    sigmas=sigmas,\n",
    "    low_thresholds=low_thresholds,\n",
    "    high_thresholds=high_thresholds,\n",
    ")\n",
    "\n",
    "\n",
    "imgs = [img2, img1]\n",
    "xlabels = [\n",
    "    \"Template\",\n",
    "    \"Normalized SSD\",\n",
    "]\n",
    "axs = plot_pictures(imgs, xlabels, 1, 2, show=False, vmin=None, vmax=None)\n",
    "\n",
    "for d in znssd:\n",
    "    axs[-1].plot(d[\"result\"][1], d[\"result\"][0], \"ro\")\n",
    "    axs[-1].add_patch(\n",
    "        patches.Rectangle(\n",
    "            (d[\"result\"][1], d[\"result\"][0]),\n",
    "            d[\"template\"].shape[1],\n",
    "            d[\"template\"].shape[0],\n",
    "            linewidth=1,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayQcua5RGuJ6"
   },
   "source": [
    "## **Question 3: Object Identification** *(12 Points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzRHZxFSnk5H"
   },
   "source": [
    "*Note: This identification part contains **query and model images** for the evaluation, which correspond to the same set of objects photographed from different viewpoints. The files **model.txt** and **query.txt** contain lists of image files arranged so that i-th model image depicts the same object as i-th query image.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj1KV3V1Gxdu"
   },
   "source": [
    "#### **Question 3.1: 3D Joint Color Histogram** *(2/12 Points)*\n",
    "\n",
    "Your task is to implement a Python function, histogramdd, from scratch. This function should compute the multidimensional histogram of a given image. The function should accept an image and a specification for the number of bins to use for each dimension. You should then divide the data into bins and count the number of data points that fall into each bin. \n",
    "\n",
    "If you want to check that your result is correct, you can compare it with the [function already implemented by NumPy](https://numpy.org/doc/stable/reference/generated/numpy.histogramdd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MmQufrp27fL"
   },
   "outputs": [],
   "source": [
    "def histogramdd(img: np.ndarray, bins: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Follow these steps:\n",
    "        1) Create bin intervals for each dimension.\n",
    "        2) Compute the shape of the histogram based on bin intervals.\n",
    "        3) Initialize the histogram as an array of zeros.\n",
    "        4) Compute the histogram for the input data.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Input image.\n",
    "        bins (int): Number of bins.\n",
    "\n",
    "    Returns:\n",
    "        histograms (np.ndarray): Histogram.\n",
    "        bin_edges (np.ndarray): Bin edges.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return histograms, bin_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd0IkObT5UDm"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9DymP-shaU7"
   },
   "outputs": [],
   "source": [
    "def histogram3dplot(h, e, fig=None):\n",
    "    \"\"\"\n",
    "    Visualize a 3D histogram\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    h: histogram array of shape (M,N,O)\n",
    "    e: list of bin edge arrays (for R, G and B)\n",
    "    \"\"\"\n",
    "    M, N, O = h.shape  # numero di bins\n",
    "    idxR = np.arange(M)\n",
    "    idxG = np.arange(N)\n",
    "    idxB = np.arange(O)\n",
    "\n",
    "    R, G, B = np.meshgrid(idxR, idxG, idxB)  # divisione per bins\n",
    "    a = np.diff(e[0])[0]\n",
    "    b = a / 2\n",
    "    R = a * R + b\n",
    "\n",
    "    a = np.diff(e[1])[0]\n",
    "    b = a / 2\n",
    "    G = a * G + b\n",
    "\n",
    "    a = np.diff(e[2])[0]\n",
    "    b = a / 2\n",
    "    B = a * B + b\n",
    "\n",
    "    colors = np.vstack((R.flatten(), G.flatten(), B.flatten())).T / 255\n",
    "    h = h / np.sum(h)\n",
    "    if fig is not None:\n",
    "        f = plt.figure(fig)\n",
    "    else:\n",
    "        f = plt.gcf()\n",
    "    ax = f.add_subplot(111, projection=\"3d\")\n",
    "    mxbins = np.array([M, N, O]).max()\n",
    "    ax.scatter(\n",
    "        R.flatten(),\n",
    "        G.flatten(),\n",
    "        B.flatten(),\n",
    "        s=h.flatten() * (256 / mxbins) ** 3 / 2,\n",
    "        c=colors,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Red\")\n",
    "    ax.set_ylabel(\"Green\")\n",
    "    ax.set_zlabel(\"Blue\")\n",
    "\n",
    "\n",
    "img = Image.open(\"images/colors.jpg\")\n",
    "img = np.array(img)\n",
    "h, e = histogramdd(img.reshape(-1, 3), bins=10)\n",
    "histogram3dplot(h, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81y1bHwiIXUF"
   },
   "source": [
    "#### **Question: 3.2: Types of Histograms** *(2/12 Points)*\n",
    "\n",
    "In this section, you are asked to implement the **GB** histogram and to correct the dx/dy histogram. Finally, you are asked to comment and compare the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bpmpn983JGvr"
   },
   "source": [
    "##### **GB Histogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygPUj08E4fS1"
   },
   "source": [
    "In this exercise, you should implement the **GB** histogram.\n",
    "\n",
    "*Note: as before, when considering GB, you should keep in mind that the range of the pixel's intensity is between $0$ and $255$*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_hist(img_color_double: np.ndarray, num_bins: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the *joint* histogram for the G and B color channels in the image.\n",
    "    The histogram should be normalized so that sum of all values equals 1,\n",
    "    assume that values in each channel vary between 0 and 255\n",
    "\n",
    "    Args:\n",
    "        img_color_double (np.ndarray): Input color image.\n",
    "        num_bins (int): Number of bins used to discretize each channel, total number of bins in the histogram should be num_bins^2.\n",
    "\n",
    "    Returns:\n",
    "        hists (np.ndarray): Joint histogram.\n",
    "\n",
    "    E.g. hists[0,9] contains the number of image_color pixels such that:\n",
    "        - their G values fall in bin 0\n",
    "        - their B values fall in bin 9\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrrLDCxs5WIm"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose and test GB histograms (histogram_module.GB_hist)\n",
    "img_color = np.array(Image.open(\"images/escher_circle.jpg\"))\n",
    "\n",
    "plt.figure(3, figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "num_bins_color = 5\n",
    "plt.subplot(1, 2, 2)\n",
    "hist_gb = gb_hist(img_color.astype(\"double\"), num_bins_color)\n",
    "plt.bar(np.array(range(1, hist_gb.size + 1)), hist_gb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJVxfVNmJZsG"
   },
   "source": [
    "##### **DX/DY Histogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlAjbn0lOeF9"
   },
   "source": [
    "In this exercise, you will find an implemented version of another type of histogram, the dx/dy one. However, **it is not correct, there are some mistakes in the code**:\n",
    "\n",
    "- function `gaussdx`: **2 mistakes**;\n",
    "- function `gauss_dxdy`: **2 mistakes**;\n",
    "- function `hist_dxdy`: **2 mistakes**.\n",
    "\n",
    "You are asked to copy each function in the corresponding cell and to correct the mistakes. Put a comment on the lines where you have made the corrections. \n",
    "Before coding, write down the first derivative of the Gaussian function.\n",
    "\n",
    "*HINT: leverage the result of the derivation to correct the mistakes in `gaussdx`*.\n",
    "\n",
    "*Note: each mistaken line counts as one mistake; a mistake can also be a missing line or a missing block of lines*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dx}g(x) &= \\frac{d}{dx}\\left[\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)\\right] = \\\\\n",
    "&= \\text{YOUR ANSWER HERE}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oK1CvuIV-41O"
   },
   "outputs": [],
   "source": [
    "def gaussdx(sigma: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function computes the first derivative of the 1D Gaussian operator.\n",
    "\n",
    "    Args:\n",
    "        sigma (float) : the standard deviation of the Gaussian filter\n",
    "\n",
    "    Returns:\n",
    "        Dx (np.ndarray): the first derivative of the 1D Gaussian operator\n",
    "        x (np.ndarray): the indexes of the 1D Gaussian operator\n",
    "    \"\"\"\n",
    "    sigma = math.ceil(sigma)\n",
    "    filter_size = 3 * sigma + 1\n",
    "\n",
    "    # Generate the index x\n",
    "    zero_pos = 3 * sigma  # the (zero_pos+1)th element is the 0 for the index\n",
    "    x = np.arange(filter_size) - zero_pos  # indexes from -3*sigma to 3*sigma\n",
    "\n",
    "    # Compute the Gaussian curve with std-dev sigma at the indexes x\n",
    "    Dx = x * np.exp(-(x**2) / (2.0 * sigma**2)) / (math.sqrt(2.0 * np.pi) * sigma)\n",
    "\n",
    "    return Dx, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that your implementation is correct, plot the result of the function with $\\sigma=3$ and compare it with the image below.\n",
    "\n",
    "![](./images/1gaussdx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first derivative of the 1D Gaussian operator\n",
    "sigma = 3\n",
    "Dx, x = gaussdx(sigma)\n",
    "plt.figure(1)\n",
    "plt.plot(x, Dx, \".-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_dxdy(img, sigma):\n",
    "    \"\"\"\n",
    "    This function applies the first derivative of the 1D Gaussian operator to the image in the x and y directions.\n",
    "\n",
    "    Args:\n",
    "        img: the input image\n",
    "        sigma: the standard deviation of the Gaussian filter\n",
    "\n",
    "    Returns:\n",
    "        img_Dx: the image after applying the first derivative of the 1D Gaussian operator in the x direction\n",
    "        img_Dy: the image after applying the first derivative of the 1D Gaussian operator in the y direction\n",
    "    \"\"\"\n",
    "\n",
    "    Gx, _ = gauss(sigma)\n",
    "    Dx, _ = gaussdx(sigma)\n",
    "\n",
    "    Gx = Gx.reshape(1, Gx.size)\n",
    "    Dx = Dx.reshape(1, Dx.size)\n",
    "\n",
    "    img_Dx = conv2(conv2(img, Dx, \"same\"), Gx, \"same\")\n",
    "    img_Dy = conv2(conv2(img, Dx, \"same\"), Gx, \"same\")\n",
    "\n",
    "    return img_Dx, img_Dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that your implementation is correct, plot the result of the function with $\\sigma=1$ and compare it with the images below.\n",
    "\n",
    "![](./images/check_gaussdxdy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = rgb2gray(np.array(Image.open(\"images/escher_circle.jpg\")))\n",
    "\n",
    "img_Dx, img_Dy = gauss_dxdy(img_color, 1)\n",
    "\n",
    "plot_pictures([img_Dx, img_Dy], [\"Dx\", \"Dy\"], 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_dxdy(img_gray, num_bins=5):\n",
    "    \"\"\"\n",
    "    This function computes the *joint* histogram of Gaussian partial derivatives of the image in x and y direction.\n",
    "    Set sigma to 3.0 and cap the range of derivative values is in the range [-6, 6].\n",
    "    The histogram should be normalized so that the sum of all values equals 1.\n",
    "\n",
    "    Args:\n",
    "        img_gray: the input image\n",
    "        num_bins: number of bins used to discretize each dimension, total number of bins in the histogram should be num_bins^2\n",
    "\n",
    "    Returns:\n",
    "        hists: the joint normalized histogram of Gaussian partial derivatives of the image in x and y direction\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(img_gray.shape) == 2, \"image dimension mismatch\"\n",
    "    assert img_gray.dtype == \"float\", \"incorrect image type\"\n",
    "\n",
    "    # Compute the first derivatives of img_gray\n",
    "    sigma = 3.0\n",
    "    img_dx, img_dy = gauss_dxdy(img_gray, sigma)\n",
    "\n",
    "    # Set the min_der and max_der to -6 and 6, which defines the ranges for quantization\n",
    "    min_der, max_der = (-6, 6)\n",
    "\n",
    "    # Flatten the 2D derivative images to 1D arrays\n",
    "    img_dx = img_dx.reshape(-1)\n",
    "    img_dy = img_dy.reshape(-1)\n",
    "\n",
    "    # Clip the min and max values to min_der and max_der respectively\n",
    "    # and shift minumum values to 0\n",
    "    img_dx = np.clip(img_dx, min_der, max_der) + max_der\n",
    "    img_dy = np.clip(img_dy, min_der, max_der)\n",
    "\n",
    "    hists = np.zeros((num_bins, num_bins), dtype=int)\n",
    "    bin_range = (max_der - min_der) / num_bins\n",
    "\n",
    "    # quantize image derivative valuer into bins\n",
    "    bin_dx = np.floor(img_dx / bin_range).astype(int)\n",
    "    bin_dy = np.floor(img_dy / bin_range).astype(int)\n",
    "    bin_dx = np.clip(bin_dx, 0, num_bins - 1)\n",
    "    bin_dy = np.clip(bin_dy, 0, num_bins - 1)\n",
    "\n",
    "    for i in range(bin_dx.size):\n",
    "        hists[bin_dx[i], bin_dy[i]] += 1\n",
    "\n",
    "    hists = hists.flatten()\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that your implementation is correct, compare it with the image below.\n",
    "\n",
    "![](./images/check_hist_dxdy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = np.array(Image.open(\"images/escher_circle.jpg\"))\n",
    "img_gray = rgb2gray(img_color.astype(\"double\"))\n",
    "\n",
    "plt.figure(5)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_color)\n",
    "\n",
    "num_bins_dxdy = 10\n",
    "plt.subplot(1, 2, 2)\n",
    "hist_dxdy_ = hist_dxdy(img_gray, num_bins_dxdy)\n",
    "plt.bar(np.array(range(1, hist_dxdy_.size + 1)), hist_dxdy_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Theoretical questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have implemented two color histograms - 3D joint and GB - and the dx/dy histogram, answer to the following questions: \n",
    "\n",
    "1. What does the dx/dy histogram represent in terms of image features?\n",
    "2. In your opinion, which of the two types of histograms (color and dx/dy) is more robust to changes in illumination? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3.3: Histogram Metrics** *(3/12 Points)*\n",
    "\n",
    "Now that you have implemented and used different types of histograms, let's consider distance functions.\n",
    "1. Write the definition of intersection distance function, $L_2$, and $\\chi^2$ distance functions.\n",
    "2. Implement each one of them.\n",
    "3. Write down some considerations on each one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the definition of each metric.\n",
    "\n",
    "* Intersection function **for unnormalized histograms**:\n",
    "\n",
    "\\begin{equation}\n",
    "\\bigcap(Q,V)=\n",
    "\\end{equation}\n",
    "\n",
    "* $L_2$ function:\n",
    "\\begin{equation}\n",
    "d(Q,V)=\n",
    "\\end{equation}\n",
    "\n",
    "* $\\chi^2$ function:\n",
    "\\begin{equation}\n",
    "\\chi^2(Q,V)= \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_intersect(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the intersection between histograms x and y.\n",
    "    Check that the distance range is [0,1].\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): Input histogram.\n",
    "        h2 (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        x (float): Intersection distance between histograms x and y.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def hist_l2(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the L2 between x and y histograms.\n",
    "    Check that the distance range in [0,sqrt(2)].\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): Input histogram.\n",
    "        h2 (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        x (float): L2 distance between x and y histograms.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def hist_chi2(h1: np.ndarray, h2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute chi2 between x and y.\n",
    "    Check that the distance range in [0,Inf].\n",
    "\n",
    "    Args:\n",
    "        h1 (np.ndarray): Input histogram.\n",
    "        h2 (np.ndarray): Input histogram.\n",
    "\n",
    "    Returns:\n",
    "        x (float): Chi2 distance between x and y.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write there your considerations about the advantages and disadvantages of each one of them, stating if each is a similarity or distance metric.\n",
    "\n",
    "--------------------------------------------\n",
    "**WRITE YOU ANSWER HERE**\n",
    "\n",
    "**Intersection distance function**\n",
    "\n",
    "**$L_2$ distance function**\n",
    "\n",
    "**$\\chi^2$ distance function**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.array(Image.open(\"model/obj100__0.png\"))\n",
    "img2 = np.array(Image.open(\"model/obj63__0.png\"))\n",
    "\n",
    "num_bins_color = 5\n",
    "hist1 = gb_hist(img1.astype(\"double\"), num_bins_color)\n",
    "hist2 = gb_hist(img2.astype(\"double\"), num_bins_color)\n",
    "\n",
    "# plot images and histograms\n",
    "plt.figure(6, figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(7, figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.array(range(1, hist1.size + 1)), hist1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.array(range(1, hist2.size + 1)), hist2)\n",
    "plt.show()\n",
    "\n",
    "metrics = np.array(\n",
    "    [hist_intersect(hist1, hist2), hist_l2(hist1, hist2), hist_chi2(hist1, hist2)]\n",
    ")\n",
    "\n",
    "# write distances to file\n",
    "# np.savetxt(\"assets/metrics.npy\", metrics)\n",
    "\n",
    "# read metrics from file\n",
    "metrics = np.loadtxt(\"assets/metrics.npy\")\n",
    "\n",
    "# print distances and compare them with the solution\n",
    "print(f\"Intersection:\\n\\t{metrics[0]}\\t{hist_intersect(hist1, hist2)}\")\n",
    "print(f\"L2:\\n\\t{metrics[1]}\\t{hist_l2(hist1, hist2)}\")\n",
    "print(f\"Chi2:\\n\\t{metrics[2]}\\t{hist_chi2(hist1, hist2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg-j-e9FNIgg"
   },
   "source": [
    "### **Question 3.4: Image Retrieval** *(3/12 Points)*\n",
    "\n",
    "Now that you have implemented and used different types of histograms, it's time to test how suitable they are for retrieving images in a query-by-example scenario.\n",
    "\n",
    "Implement a function called `find_best_match` that returns the closest model images for each query image.\n",
    "The function takes input string parameters, identifying the distance function, histogram function, and the number of histogram bins.\n",
    "\n",
    "*Note: See comments at the beginning of the `find_best_match` function for more details.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBYePNzhWbkA"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7--k70mUL_Qz"
   },
   "outputs": [],
   "source": [
    "def is_grayvalue_hist(hist_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Handle function to discriminate when your input\n",
    "    function is in gray_scale or colors.\n",
    "\n",
    "    Args:\n",
    "        hist_name (str): histogram name.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the histogram is in gray_scale, False otherwise.\n",
    "    \"\"\"\n",
    "    if hist_name == \"grayvalue\" or hist_name == \"dxdy\":\n",
    "        return True\n",
    "    elif hist_name == \"rgb\" or hist_name == \"gb\":\n",
    "        return False\n",
    "    else:\n",
    "        assert False, \"unknown histogram type\"\n",
    "\n",
    "\n",
    "def get_hist_by_name(img: np.ndarray, num_bins_gray: int, hist_name: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Handle function to get the correct historgam function\n",
    "    by his name.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): input image.\n",
    "        num_bins_gray (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: histogram.\n",
    "    \"\"\"\n",
    "    # if hist_name == \"rgb\":\n",
    "    #     return rgb_hist(img, num_bins_gray)\n",
    "    if hist_name == \"gb\":\n",
    "        return gb_hist(img, num_bins_gray)\n",
    "    elif hist_name == \"dxdy\":\n",
    "        return hist_dxdy(img, num_bins_gray)\n",
    "    else:\n",
    "        assert False, \"unknown hist type: %s\" % hist_name\n",
    "\n",
    "\n",
    "def get_dist_by_name(x: np.ndarray, y: np.ndarray, dist_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Handle function to get the correct distance function\n",
    "    by his name.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): input histogram.\n",
    "        y (np.ndarray): input histogram.\n",
    "\n",
    "    Returns:\n",
    "        float: distance.\n",
    "    \"\"\"\n",
    "    if dist_name == \"chi2\":\n",
    "        return hist_chi2(x, y)\n",
    "    elif dist_name == \"intersect\":\n",
    "        return 1 - hist_intersect(x, y)\n",
    "    elif dist_name == \"l2\":\n",
    "        return hist_l2(x, y)\n",
    "    elif dist_name == \"all\":\n",
    "        pass\n",
    "    else:\n",
    "        assert False, \"unknown distance: %s\" % dist_name\n",
    "\n",
    "\n",
    "def read_files(\n",
    "    model_path: str = \"assets/model.txt\", query_path: str = \"assets/query.txt\"\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Handle function to read query and model files.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): path to the model file.\n",
    "        query_path (str): path to the query file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: query images and model images.\n",
    "    \"\"\"\n",
    "    with open(model_path) as fp:\n",
    "        model_images = fp.readlines()\n",
    "    model_images = [x.strip() for x in model_images]\n",
    "\n",
    "    with open(query_path) as fp:\n",
    "        query_images = fp.readlines()\n",
    "    query_images = [x.strip() for x in query_images]\n",
    "\n",
    "    return query_images, model_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGTzGSQt_LU1"
   },
   "outputs": [],
   "source": [
    "# note: use functions 'get_dist_by_name', 'get_hist_by_name' and 'is_grayvalue_hist' to obtain\n",
    "#       handles to distance and histogram functions, and to find out whether histogram function\n",
    "#       expects grayvalue or color image\n",
    "\n",
    "\n",
    "def compute_histograms(\n",
    "    image_list: List[np.ndarray], hist_type: str, hist_isgray: bool, num_bins: int\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute the histogram for each image in image_list.\n",
    "\n",
    "    Args:\n",
    "        image_list (List[np.ndarray]): list of images.\n",
    "        hist_type (str): histogram type.\n",
    "        hist_isgray (bool): True if the histogram is in gray_scale, False otherwise.\n",
    "        num_bins (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        image_hist (List[np.ndarray]): list of histograms.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return image_hist\n",
    "\n",
    "\n",
    "def find_best_match(\n",
    "    model_images: List[str],\n",
    "    query_images: List[str],\n",
    "    dist_type: str,\n",
    "    hist_type: str,\n",
    "    num_bins: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Function to find the best match for each image in the\n",
    "    query folder.\n",
    "\n",
    "    Args:\n",
    "        model_images (List[str]): list of strings with the path of model images.\n",
    "        query_images (List[str]): list of strings with the path of query images.\n",
    "        dist_type (str): a string to represent the name of the distance you want to use. Should be one among \"l2\", \"intersect\", \"chi2\".\n",
    "        hist_type (str): a string to represent the name of the histogram you want to use. Should be one among \"grayvalue\", \"rgb\", \"rg\", \"dxdy\".\n",
    "        num_bins (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        best_match (np.ndarray): list containing in each position the index of the retrieved best matching image.\n",
    "        D (np.ndarray): Matrix with |model_images| rows and |query_images| columns containing the scores of each matching.\n",
    "    #\"\"\"\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return best_match, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EInVn-br5h1u"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwhtN9h5zFsw"
   },
   "outputs": [],
   "source": [
    "# model_images - list of file names of model images\n",
    "# query_images - list of file names of query images\n",
    "\n",
    "query_images, model_images = read_files()\n",
    "\n",
    "dist_type = \"intersect\"\n",
    "hist_type = \"gb\"\n",
    "num_bins = 10\n",
    "\n",
    "[best_match, D] = find_best_match(\n",
    "    model_images, query_images, dist_type, hist_type, num_bins\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Indexes of correct retrieved images is:\\n \",\n",
    "    *np.where(best_match == np.arange(len(query_images)))\n",
    ")\n",
    "print(\n",
    "    \"The Recognition rate is\",\n",
    "    sum(best_match == np.arange(len(query_images))) / len(query_images),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82QRWPM95lpW"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQD3_DRtsjlq"
   },
   "source": [
    "### **#2 Report** *(2/12 Points)*\n",
    "\n",
    "Experiment with different functions and numbers of histogram bins, and find a combination that works best. **Submit the summary of your experiments in a report as part of your solution.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mt8zvGFbsjlu"
   },
   "source": [
    "----------------------------\n",
    "\n",
    "**Fill the table below**\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "|  | Number of Bins | Metric(Distance Metric) | Accuracy |\n",
    "|---|---|---|---|\n",
    "| 1 |  |  |  |\n",
    "| 2 |  |  |  |\n",
    "| 3 |  |  |  |\n",
    "| ... |  |  |  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmH2DfprUco8"
   },
   "source": [
    "## ***Bonus* Question 4: Performance Evaluation** *(5 Points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKUShXgL17MW"
   },
   "source": [
    "In this bonus question, your goal is to implement different types of metrics to evaluate the performance of a binary classificator.\n",
    "\n",
    "For the purpose of this exercise you don't need to know the inner workings of the ML model, therefore imagine to have a black box model that estimates the probability of an event occurring, such as the sky being clear or not, based on a given dataset of independent variables. Since the outcome is a probability, the dependent variable is bounded between 0 and 1.\n",
    "\n",
    "In order to compute a performance score (e.g., accuracy), you need to compare your predictions with the true values. So you need to convert the predicted probabilities into 0s and 1s by means of a threshold.\n",
    "\n",
    "What you have to do is the following:\n",
    "- **compute the performance** of the model with all the possible tresholds in the interval \\[0.0, 1.0\\] with increments of 0.5\n",
    "- **analyze** how the metrics vary at different thresholds and **write a report** on your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4.1: Closest Neighbours** *(2/5 Points)*\n",
    "\n",
    "Implement a function `show_neighbors`, which inputs a list of model images and a list of query images.\n",
    "For each query image, the function has to output a visualization of 5 model images which are most similar to the query image according to the specified distance metric.\n",
    "\n",
    "*HINT: use the function `find_best_match`.*\n",
    "\n",
    "![](images/neighbors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_neighbors(\n",
    "    model_images: List[str],\n",
    "    query_images: List[str],\n",
    "    dist_type: str,\n",
    "    hist_type: str,\n",
    "    num_bins: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For each image file from 'query_images' find and visualize the 5 nearest images from 'model_image'.\n",
    "\n",
    "    Note: use the previously implemented function 'find_best_match'\n",
    "\n",
    "    Args:\n",
    "        model_images (List[str]): list of strings with the path of model images.\n",
    "        query_images (List[str]): list of strings with the path of query images.\n",
    "        dist_type (str): a string to represent the name of the distance you want to use. Should be one among \"l2\", \"intersect\", \"chi2\".\n",
    "        hist_type (str): a string to represent the name of the histogram you want to use. Should be one among \"grayvalue\", \"rgb\", \"rg\", \"dxdy\".\n",
    "        num_bins (int): number of bins for the gray_scale histogram.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize nearest neighbors\n",
    "query_images_vis = [query_images[i] for i in np.array([0, 4, 9])]\n",
    "show_neighbors(model_images, query_images_vis, dist_type, hist_type, num_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtJ7oghm2Yrl"
   },
   "source": [
    "### **Question 4.2: Performance Evaluation** *(2/5 Points)*\n",
    "\n",
    "Write the code to compute the metrics for performance evaluation, then run the provided code cell to check if your results are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLHgoIpwPO2Z"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./assets/ionosphere.data\", header=None)\n",
    "X = data[data.columns[:34]]\n",
    "y = data[data.columns[-1]]\n",
    "y = np.array([0 if value == \"b\" else 1 for value in y])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2THGCavYv6s"
   },
   "outputs": [],
   "source": [
    "def my_accuracy_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the accuracy score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: accuracy score.\n",
    "    \"\"\"\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def my_precision_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the precision score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: precision score.\n",
    "    \"\"\"  #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    return precision\n",
    "\n",
    "\n",
    "def my_recall_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the recall score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: recall score.\n",
    "    \"\"\"  #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    return recall\n",
    "\n",
    "\n",
    "def my_f1_score(y_true: list, y_pred: list) -> float:\n",
    "    \"\"\"\n",
    "    Compute the f1 score.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"  #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    return f1\n",
    "\n",
    "\n",
    "def my_confusion_matrix(y_true: list, y_pred: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_true (list): list of true labels.\n",
    "        y_pred (list): list of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: confusion matrix.\n",
    "    \"\"\"  #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "    return np.array(matrix, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnJk9tUnPKJv"
   },
   "source": [
    "--------------------------------------------\n",
    "**Do not write below this line just run it**\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ny4AMD42Uhs9"
   },
   "outputs": [],
   "source": [
    "# CHECK IF YOUR METRICS ARE CORRECT BY RUNNING THIS CODE CELL\n",
    "\n",
    "\n",
    "def compare_metric(my_metric_fun, metric_fun, y_test, preds):\n",
    "    try:\n",
    "        if my_metric_fun.__name__ != \"my_confusion_matrix\":\n",
    "            assert round(my_metric_fun(y_test, preds), 4) == round(\n",
    "                metric_fun(y_test, preds), 4\n",
    "            )\n",
    "        else:\n",
    "            assert np.array_equal(\n",
    "                my_metric_fun(y_test, preds), metric_fun(y_test, preds)\n",
    "            )\n",
    "        print(f\"{my_metric_fun.__name__} is correct\")\n",
    "    except:\n",
    "        print(f\"{my_metric_fun.__name__} is wrong\")\n",
    "\n",
    "\n",
    "preds = np.array([0 if p < 0.5 else 1 for p in y_pred])\n",
    "compare_metric(my_accuracy_score, accuracy_score, y_test, preds)\n",
    "compare_metric(my_precision_score, precision_score, y_test, preds)\n",
    "compare_metric(my_recall_score, recall_score, y_test, preds)\n",
    "compare_metric(my_f1_score, f1_score, y_test, preds)\n",
    "compare_metric(my_confusion_matrix, confusion_matrix, y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNGLDCu-2e_j"
   },
   "source": [
    "### **Question 4.3: Analysis and Report** *(1/5 Points)*\n",
    "\n",
    "Write the code to compute the metrics all the possible tresholds in the interval (0.0, 1.0) with increments of 0.5.  \n",
    "Ideally, you should put everything into a pandas DataFrame and print it for a better visualization.  \n",
    "Then, write a report analyzing you your results. You have complete freedom on your analysis.\n",
    "\n",
    "Imagine also to be in a medical scenario where your model is predicting the presence or not of a desease and try to answer to the following questions:\n",
    "- What is the real life trade-off between high precision and high recall? What would you choose?\n",
    "- Why isn't the accuracy an appropriate measure in such scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('freqtrade')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e2bda8d489e6a73433c4541016be4039530b57fe4140c173ceda33bc658dbe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
